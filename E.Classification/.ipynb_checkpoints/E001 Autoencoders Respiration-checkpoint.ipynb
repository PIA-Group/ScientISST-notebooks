{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div  style=\"color:#303030;font-family:'arial blACK', sans-serif,monospace; text-align: center; padding: 50px 0; vertical-align:middle;\" > <img src=\"https://www.nicepng.com/png/full/204-2043038_white-lightbulb-icon-light-bulb-icon-white.png\" style=\" background:#00a0e4;border-radius:10px;width:150px;text-align:left; margin-left:10%\"  /> <span style=\"position:relative; bottom:70px; margin-left:5%\"> Analysis of Time Series Biosignals <br> using Autoencoders </span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "<br>\n",
    "<div style=\"width:100%; background:#00a0e4;font-family:'arial black',monospace; text-align: center; padding: 7px 0; border-radius: 5px 50px;margin-top:-15px\" >  </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this example we will perform Apnea Detection using AutoEncoders to learn respiration morphology. This notebook will guide you through a morphological approach to analyze biosignals and extract information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\"> 1. Background </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoders are neural networks with encoding layers and decoding layers which try to find a compact representation of the data by comparing the input with the outpt of the network. The encoding layers try to represent the input with lesser nodes reaching the smallest layer usually called bottleneck. Whereas the decoding layers take the bottleneck layer and reconstruct the original data. \n",
    "\n",
    "To learn more about autoencoders:\n",
    "  - [Theoric explanation](https://towardsdatascience.com/auto-encoder-what-is-it-and-what-is-it-used-for-part-1-3e5c6f017726)\n",
    "  - [More info](https://towardsdatascience.com/generating-images-with-autoencoders-77fd3a8dd368)\n",
    "  \n",
    "The application of Autoencoders to biosignals is useful to find a good representation of the data just by its morphological structure. Then, when there is a significant change in morphology, we can assess if its an anomaly, artifact, or particular disease we might be evaluating. \n",
    "  \n",
    " ![alt text ](https://i.ibb.co/F7Hkfzm/ae-scheme.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\"> 2. Objectives</div>\n",
    "* Create an autoencoder to learn the respiratory pattern \n",
    "* Perform apnea detection using correlation and supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Experimental\n",
    "<br>\n",
    "<div style=\"width:100%; background:#00a0e4;font-family:'arial black',monospace; text-align: center; padding: 7px 0; border-radius: 5px 50px;margin-top:-15px\" >  </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section should guide the students during their experimental procedure, and contain the most relevant content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\">  1. Requirements (optional)</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the libraries required should be installed, using the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install biosppy >/dev/null 2>&1\n",
    "!pip install tensorflow >/dev/null 2>&1\n",
    "!pip install keras >/dev/null 2>&1\n",
    "!pip install sklearn >/dev/null 2>&1\n",
    "!pip install mpld3 >/dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import biosppy\n",
    "import tensorflow\n",
    "import keras\n",
    "import sklearn\n",
    "import mpld3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\">  2. Data Loading </div>\n",
    "\n",
    "To perform this task we will use the files 'data_sep' and 'labels_sep' provided [here](https://github.com/MarianaAbreu/BioSPPy/tree/master/examples).\n",
    "\n",
    "The 'data_sep' contains respiration signal segmented in one minute windows, which was already filtered, normalized to [-1,1] and resampled to 1000 points. \n",
    "\n",
    "The 'label_sep' contains respectively the label information of each 'data_sep' sample, regarding to the breathing pattern: 'N' is its normal breathing and 'A' if it is a breath-hold period (apnea).\n",
    "\n",
    "Both files are divided in a training set with 600 samples (40 users) and a testing set with 75 samples (5 users)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('data_sep', 'rb'))\n",
    "labels = pickle.load(open('label_sep', 'rb'))\n",
    "print('\\nTesting set ' + str(len(labels[1])) + ' users, labels: \\n')\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\">   3. Data Visualization </div>\n",
    "\n",
    "Visualize normal and apnea samples to understand the differences in morphologies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\"> 3.1. Plot Example </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for plotting\n",
    "index_1 = 2\n",
    "index_2 = 12\n",
    "x1 = data[0][index_1]\n",
    "x2 = data[0][index_2]\n",
    "# plot\n",
    "plt.title('Sample of breathing and apnea', {'size':20})\n",
    "plt.xlabel('Time (s)', color=\"#00a0e4\")\n",
    "plt.ylabel('Amplitude', color=\"#00a0e4\")\n",
    "plt.plot(x1, label=labels[0][index_1], color=\"#00bfc2\")\n",
    "plt.plot(x2, label=labels[0][index_2], color=\"#5756d6\")\n",
    "plt.legend()\n",
    "plt.savefig('resp.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\">   4. Autoencoder Creation </div>\n",
    "\n",
    "To train the autoencoder we will need to choose the following parameters: \n",
    "* Number of layers and number of nodes in each layer \n",
    "* Activation function\n",
    "* Optimization function\n",
    "* Error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\"> 4.1. Autoencoder creation   </div>\n",
    "\n",
    "The function \"autoencoder\" was created to receive the common parameters of a neural network and create the autoencoder. The advantage of this function is the ability to be adapted to different number of layers and nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "def autoencoder_(encoding_dim=50, input_len=1000, list_layers=[500,250,50], a_fun='tanh', \n",
    "                optimizer='adam', loss='cosine_similarity', x_train=None, x_test=None, label='', epochs=200):\n",
    "    \"\"\"\n",
    "    encoding_dim: number of nodes in the smallest layer (bottleneck)\n",
    "    input_len: size of input samples\n",
    "    list_layers: list of the nodes in each encoding layer, the number of nodes of the decoding layers are mirrowed from this\n",
    "    a_fun: activation function 'tanh', 'sigmoid', 'relu',...\n",
    "    optimizer: usually 'adam'\n",
    "    loss function: 'cosine_similarity', 'mse', 'cross_entropy', ...\n",
    "    \"\"\"\n",
    "\n",
    "    if sorted(list_layers, key=int, reverse=True) != list_layers:\n",
    "        print('\\nList should be in order!\\n')\n",
    "    #Encoder layers creation    \n",
    "    input_sig = Input(shape=(input_len,))\n",
    "    \n",
    "    encoded = Dense(list_layers[0], activation = a_fun)(input_sig)\n",
    "    \n",
    "    network = list_layers + list_layers[::-1][1:] + [input_len]\n",
    "    \n",
    "    for nt in list_layers[1:]:\n",
    "        encoded = Dense(nt, activation=a_fun)(encoded)\n",
    "        \n",
    "    #Encoder layers creation\n",
    "    #\"decoded\" is the lossy reconstruction of the input\n",
    "    inverse_layers = list_layers[::-1][1:] + [input_len]\n",
    "    decoded = Dense(inverse_layers[0], activation=a_fun)(encoded)\n",
    "    for ll in inverse_layers[1:]:\n",
    "        decoded = Dense(ll, activation=a_fun)(decoded)\n",
    "\n",
    "    autoencoder = Model(input_sig, decoded)\n",
    "    ##Let's also create a separate encoder model as well as the decoder model:\n",
    "    encoder = Model(input_sig, encoded)\n",
    "    encoded_input = Input(shape=(encoding_dim,))\n",
    "\n",
    "    dec_layers = autoencoder.layers[len(list_layers)+1:]\n",
    "    decoder_output = dec_layers[0](encoded_input)\n",
    "    for dl in dec_layers[1:]:\n",
    "        decoder_output = dl(decoder_output)\n",
    "        \n",
    "    decoder = Model(encoded_input,decoder_output)\n",
    "\n",
    "    ##First, we'll configure our model to use a per-pixel binary crossentropy loss, and the Adadelta optimizer\n",
    "    autoencoder.compile(optimizer=optimizer,loss=loss)\n",
    "\n",
    "    print('\\nAutoencoder Created:')\n",
    "    print('Layers: ' + str(list_layers))\n",
    "    print('Input Length: ' + str(input_len))\n",
    "    print('Compression: ' + str(encoding_dim))\n",
    "    print('Activation: ' + str(a_fun))\n",
    "    print('Optimizer: ' + str(optimizer))\n",
    "    print('Loss: ' + str(loss) +'\\n')\n",
    "\n",
    "    autoencoder.fit(x_train,x_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=100,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test, x_test))\n",
    "    return encoder, decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\"> 4.2. Autoencoder train   </div>\n",
    "\n",
    "To train the autoencoder we will only 'N' samples from data[0], which is the training set and we will separate in a train and a validation set with a proportion of 70/30. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_N = np.argwhere(labels[0] == 'N')\n",
    "data_N = data[0][index_N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#00bfc2;font-family:'arial', monospace; text-align: center; padding: 10px 0; border-radius:10px; width:70%; margin:auto \" >\n",
    "  <span style=\"font-size:20px;position:relative;color:white; \">  Note </span> <br>\n",
    "  <div style=\"background:#a8e0e0;\"> \n",
    "    The autoencoder training will show a line for each epoch, showing the loss for train and validation sets. To hide this information, uncomment the part between '#---', which will create a function to hide all information.     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#separate the train data in the train and validation sets for the autoencoder\n",
    "data_train, data_val = train_test_split(data_N, test_size=0.3)\n",
    "\n",
    "#---\n",
    "#import sys, os\n",
    "#from contextlib import contextmanager\n",
    "#@contextmanager\n",
    "#def suppress_stdout():\n",
    "#    with open(os.devnull, \"w\") as devnull:\n",
    "#        old_stdout = sys.stdout\n",
    "#        sys.stdout = devnull\n",
    "#        try:  \n",
    "#            yield\n",
    "#        finally:\n",
    "#            sys.stdout = old_stdout\n",
    "#\n",
    "#with suppress_stdout():\n",
    "#---\n",
    "encoder, decoder = autoencoder_(x_train=data_train, x_test=data_val, epochs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#62d321;font-family:'arial', monospace; text-align: center; padding: 10px 0; border-radius:10px; width:70%; margin:auto \" >\n",
    "  <span style=\"font-size:20px;position:relative;color:white; \"> Explore </span> <br>\n",
    "  <div style=\"background:#c2e8ac;\"> \n",
    "    The parameters in default were particularized for this analysis, however other might improve results even further. Experiment with the parameters with the options available at:  \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Loss functions](https://keras.io/api/losses/)\n",
    "\n",
    "[Activation functions](https://keras.io/api/layers/activations/)\n",
    "\n",
    "[Optimizers](https://keras.io/api/optimizers/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\"> 4.3. Morphological Analysis   </div>\n",
    "\n",
    "Using the outputs of the 'autoencoder' function we will take the original test and train data once again. Preferably, for this part we should use only new data, however, since our dataset is small, we will use the training set (data[0]) to train the supervised learning model, whereas the testing set (data[1]) will be used for the first time to evaluate the overall algorithm.\n",
    "\n",
    "In the plotting we see how an autoencoder trained in breathing samples tries to reconstruct an apnea sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_test = encoder.predict(data[1])\n",
    "dec_test = decoder.predict(enc_test)\n",
    "enc_train = encoder.predict(data[0])\n",
    "dec_train = decoder.predict(enc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for plotting\n",
    "index = 12\n",
    "x1 = data[1][index]\n",
    "x2 = dec_test[index]\n",
    "# plot\n",
    "plt.title('Sample of breathing and apnea', {'size':20})\n",
    "plt.xlabel('Time (s)', color=\"#00a0e4\")\n",
    "plt.ylabel('Amplitude', color=\"#00a0e4\")\n",
    "plt.plot(x1, label=labels[0][index_1], color=\"#00bfc2\")\n",
    "plt.plot(x2, label=labels[0][index_2], color=\"#5756d6\")\n",
    "plt.legend()\n",
    "plt.savefig('resp.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#62d321;font-family:'arial', monospace; text-align: center; padding: 10px 0; border-radius:10px; width:70%; margin:auto \" >\n",
    "  <span style=\"font-size:20px;position:relative;color:white; \"> Explore </span> <br>\n",
    "  <div style=\"background:#c2e8ac;\"> \n",
    "    What happens if the Autoencoder is trained with the entire train data instead of only 'N' samples? And what if it is only trained on 'A' samples? Change the first cell of section 4.2 Autoencoder train, to explore this different options.     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\">  4.4. Input/Output Correlation   </div>\n",
    "\n",
    "Through pearson correlation, we will compare the data used as input (data[0], data[1]) to the correspondant reconstructed output (dec_train, dec_test). Instead of computing just one value of correlation for the entire sample, we will divide the sample in 10 segments and evaluate the correlation inside each segment. \n",
    "\n",
    "![alt_text](https://i.ibb.co/qM8xPq6/correlation-scheme2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_size = 10 \n",
    "cs = int(1000/corr_size)\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "train_cl, test_cl, y_train_new, y_test_new = [], [], [], []\n",
    "\n",
    "#correlation in training set\n",
    "for d in range(len(dec_train)):\n",
    "    corr_train = [pearsonr(dec_train[d][i:i+cs],data[0][d][i:i+cs])[0] for i in range(0,len(dec_train[d]),cs)]\n",
    "    if np.isfinite(corr_train).all():\n",
    "        train_cl += [corr_train]\n",
    "        y_train_new += [labels[0][d]]\n",
    "\n",
    "#correlation in the testing set\n",
    "for d in range(len(dec_test)):\n",
    "    corr = [pearsonr(dec_test[d][i:i+cs],data[1][d][i:i+cs])[0] for i in range(0,len(dec_test[d]),cs)]\n",
    "    if np.isfinite(corr).all():\n",
    "        test_cl += [corr]\n",
    "        y_test_new += [labels[1][d]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#62d321;font-family:'arial', monospace; text-align: center; padding: 10px 0; border-radius:10px; width:70%; margin:auto \" >\n",
    "  <span style=\"font-size:20px;position:relative;color:white; \"> Explore </span> <br>\n",
    "  <div style=\"background:#c2e8ac;\"> \n",
    "    The correlation size = 10 is good for this signal since it seems to encapsulate breathing cycles, however other correlation sizes might also be interesting to evaluate. Change the correlation size and see its effect on the classifier performance in the next section.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\">   5. Supervised Learning   </div>\n",
    "\n",
    "Train a supervised learning classifier to discriminate between 'N' samples and 'A' samples based solely on the correlation vector previously computed (train_cl, test_cl), and the respective label (labels[0], labels[1])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(train_cl, labels[0].ravel())\n",
    "\n",
    "y_pred = classifier.predict(test_cl)\n",
    "score_acc = accuracy_score(labels[1], y_pred)\n",
    "\n",
    "print(\" --- Accuracy: \" + str(score_acc) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#62d321;font-family:'arial', monospace; text-align: center; padding: 10px 0; border-radius:10px; width:70%; margin:auto \" >\n",
    "  <span style=\"font-size:20px;position:relative;color:white; \"> Explore </span> <br>\n",
    "  <div style=\"background:#c2e8ac;\"> \n",
    "    Other classifiers might also produce solid results, experiment them and their parameters to achieve better results.      \n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background:#fada5e;font-family:'arial', monospace; text-align: center; padding: 10px 0; border-radius:10px; width:70%; margin:auto \" >\n",
    "  <span style=\"font-size:20px;position:relative;color:white; \">  Warning! </span> <br>\n",
    "  <div style=\"background:#fff4c9;\"> \n",
    "    Our initial data was already separated in a training set and testing set. However to perform solid experiments, we should repeat the process, changing the data within both sets, in order to have a performance result more representative of this problem.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Explore\n",
    "<br>\n",
    "<div style=\"width:100%; background:#00a0e4;font-family:'arial black',monospace; text-align: center; padding: 7px 0; border-radius: 5px 50px;margin-top:-15px\" >  </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\">  1. Final Notes </div>\n",
    "\n",
    "In this notebook we create an autoencoder to understand respiratory signal's morphology and use it to distinguish apneas from breathing samples. This example can be applied to other time series and classification tasks, even using the bottleneck representation as features instead of the correlation analysis. Thus, many options are available to use autoencoders or other new algorithms as substitutes for feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\">  2. Quiz </div>\n",
    "\n",
    "1. Use the bottleneck representation (enc_train and enc_test) as input to the classifier.\n",
    "<br><br>\n",
    "2. Use cross validation to evaluate the performance critically.\n",
    "<br><br>\n",
    "3. Apply this technique to another dataset and problem of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"color:#00a0e4;\">  3. Further Reading  </div>\n",
    "\n",
    "1. Check the full paper were this technique is explained thoroughly (link paper)\n",
    "2. Explore supervised through feature engineering (link Signal Classification using SL)\n",
    "3. Explore other neural networks applied to biosignals (link prof.Andr√© Martins notebook)\n",
    "4. Explore how to extract datasets from public databases for upgrades to this challenges (link Tiago)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:115px; background:white;border-radius:10px;text-align:center\"> \n",
    "\n",
    "<img src=\"https://www.lx.it.pt/~asmc/predict/images/IT.png\" alt=\"it\" style=\"position: relative; margin-left: 10px; bottom:-55px;max-width:150px;height:auto;\"/> \n",
    "<img src=\"https://cqe.tecnico.ulisboa.pt/files/files/logos/IST_A_RGB_POS.png\"\n",
    "         alt=\"alternate text\" \n",
    "         style=\"position: relative; margin-left: 10px;  bottom:-50px; width:150px;height:auto;\"/>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; \">\n",
    "<div style=\"background:#00a0e4;color:white;font-family:'arial', monospace; text-align: center; padding: 50px 0; border-radius:10px; height:10px; width:100%; float:left \" >\n",
    "<span style=\"font-size:12px;position:relative; top:-25px\">  Please provide us your feedback <span style=\"font-size:14px;position:relative;COLOR:WHITE\"> [here](https://forms.gle/C8TdLQUAS9r8BNJM8)</span>.</span> \n",
    "<br>\n",
    "<span style=\"font-size:17px;position:relative; top:-20px\">  Suggestions are welcome! </span> \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
